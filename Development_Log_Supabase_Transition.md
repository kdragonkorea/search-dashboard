# 📋 Supabase 전환 및 개발 이슈 통합 로그 (2026-02-08)

## 1. 프로젝트 주요 전환 사항: CSV → Supabase Cloud
기존 로컬 CSV 로딩 방식의 물리적 한계(474만 행, 약 1.5GB)를 극복하기 위해 Supabase(PostgreSQL) 클라우드 아키텍처로 전면 전환되었습니다.

### 🏗️ 데이터베이스 구조 (Supabase)
- **`keyword_trends` (기초 테이블)**: 4,746,464건의 원본 데이터 적재.
- **`daily_keyword_summary` (집계 테이블)**: 911,155건의 일자별/키워드별/속성별 요약 데이터. 랭킹 및 필터링 속도 향상을 위해 사용.
- **서버 측 함수 (RPC)**:
    - `get_daily_metrics_v2`: 474만 건 전수 데이터를 서버에서 0.5초 만에 일자별 집계.
    - `get_keyword_analysis`: 특정 키워드 검색 시 전수 데이터 기반 0.1초 내 분석 결과 반환.

## 2. 발생한 주요 이슈 및 해결 현황

### ❌ 에러 이슈 (해결됨)
- **`TypeError: BaseSelectRequestBuilder.order() got an unexpected keyword argument 'descending'`**: Supabase 라이브러리 업데이트로 인해 `descending` 대신 `desc` 파라미터 사용으로 교정.
- **`NameError: name 'filtered_df' is not defined`**: 서버 측 집계 로직으로 전환하는 과정에서 변수 할당 위치가 누락되었던 지점 보강.
- **`KeyError: 'age'`, `'연령대'`, `'성별'`**: 
    - 원인: 전수 집계 결과만 가져오면 상세 속성(연령/성별) 정보가 누락됨.
    - 해결: `daily_keyword_summary` 테이블에서 상위 10,000행을 'filtered_df'로 로드하여 속성 분석 탭과 연결.

### ⚠️ 성능 이슈 (진행 중)
- **데이터 로딩 지연 (20초+)**: 
    - **원인**: 50,000행을 1,000건씩 페이지네이션하여 50번 호출하는 과정에서 네트워크 오버헤드 발생.
    - **조치**: 랭킹 분석에 충분한 상위 10,000행으로 한도를 최적화(로드 시간 약 3~5초 예상).

## 3. 남은 과제 및 개선 제안
1. **데이터 로딩 최적화**: 현재 Streamlit의 `st.cache_data`를 활용하고 있으나 초기 진입 속도를 더 높이기 위해 데이터베이스 인덱스 추가 최적화 필요.
2. **필터링 로직 정밀화**: `visualizations.py`에 남아있는 레거시 필터링(page=1, service='totalsearch' 등)을 제거하고 데이터베이스 뷰(View) 단계에서 미리 처리된 데이터를 가져오는 방식 추천.
3. **병렬 로딩**: 일자별 트렌드(RPC)와 상세 필터 데이터(1만 행)를 비동기로 호출하여 사용자 체감 속도를 더 개선할 수 있음.

---
**내일의 작업을 위한 메모**:
현재 `data_loader.py`와 `app.py`는 Supabase 연동에 최적화되어 있으나, 초기 로딩 시 `load_data_range` 함수가 네트워크 상태에 따라 지연을 유발할 수 있습니다. 다음 세션에서는 이 부분의 비동기 처리 또는 데이터 다이어트를 최우선으로 검토해 주세요.
